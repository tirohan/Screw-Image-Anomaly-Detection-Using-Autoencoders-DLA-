{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eLXvlhPqnNM",
        "outputId": "6d915d88-7fb9-4d1f-8257-def664252125"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries"
      ],
      "metadata": {
        "id": "V1R088IUbWtT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "from tensorboardX import SummaryWriter\n",
        "import tensorflow as tf\n",
        "import tensorflow.summary\n",
        "from tensorflow.summary import scalar\n",
        "from tensorflow.summary import histogram\n",
        "import mlflow.pytorch\n",
        "import seaborn as sns\n",
        "from datetime import date\n",
        "today = str(date.today())"
      ],
      "metadata": {
        "id": "eGQYH9mYZjuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function \n",
        "from __future__ import division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "print(\"PyTorch Version: \",torch.__version__)\n",
        "print(\"Torchvision Version: \",torchvision.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOUwIlmsZjwW",
        "outputId": "4678eb91-7e75-41d1-e26f-5d2473ca1b31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Version:  2.0.0+cu118\n",
            "Torchvision Version:  0.15.1+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the VAE model\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dim):\n",
        "        super(VAE, self).__init__()\n",
        "        \n",
        "        # Encoder network\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, latent_dim*2)\n",
        "        )\n",
        "        \n",
        "        # Decoder network\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, input_dim)\n",
        "        )\n",
        "        \n",
        "        # Latent dimension\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def encode(self, x):\n",
        "        # Encode input to mean and variance\n",
        "        h = self.encoder(x)\n",
        "        mu, log_var = torch.split(h, self.latent_dim, dim=1)\n",
        "        return mu, log_var\n",
        "    \n",
        "    def decode(self, z):\n",
        "        # Decode latent variable to output\n",
        "        x = self.decoder(z)\n",
        "        return x\n",
        "    \n",
        "    def reparameterize(self, mu, log_var):\n",
        "        # Reparameterize the distribution\n",
        "        std = torch.exp(0.5*log_var)\n",
        "        eps = torch.randn_like(std)\n",
        "        z = mu + eps*std\n",
        "        return z\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Forward pass through the network\n",
        "        mu, log_var = self.encode(x)\n",
        "        z = self.reparameterize(mu, log_var)\n",
        "        x_recon = self.decode(z)\n",
        "        return x_recon, mu, log_var\n",
        "\n",
        "vae = VAE()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "MOY7MVfJuCIp",
        "outputId": "888cf7b3-e580-43ac-d35b-2148fb68509b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-4073cc76d3da>\u001b[0m in \u001b[0;36m<cell line: 56>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx_recon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_var\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mvae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'input_dim' and 'latent_dim'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Pipeline"
      ],
      "metadata": {
        "id": "Lk0vGEv8b39D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/MyDrive/Datasets/Screw Dataset/archive/'\n",
        "\n",
        "# Models to choose from [resnet, alexnet, vgg16, squeezenet, densenet, inception]\n",
        "model_name = \"alexnet\"\n",
        "num_classes = 2\n",
        "batch_size = 32\n",
        "num_epochs = 20\n",
        "feature_extract = False\n",
        "pre_trained=True\n",
        "\n",
        "save_model='/content/drive/MyDrive/Datasets/'\n",
        "save_confusion_mat='/content/drive/MyDrive/Datasets/densenet_17_mat.csv'"
      ],
      "metadata": {
        "id": "3rN7VeayZj02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_scalar(name, value, step):\n",
        "    \"\"\"Log a scalar value to both MLflow and TensorBoard\"\"\"\n",
        "    mlflow.log_metric(name, value, step=step)"
      ],
      "metadata": {
        "id": "twVek1ajbKNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "    test_acc_history = []\n",
        "    \n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'test']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "\n",
        "                    if is_inception and phase == 'train':\n",
        "                        \n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                \n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "            if phase=='train':\n",
        "                log_scalar('training_loss', epoch_loss, epoch)\n",
        "                log_scalar('training_accuracy', float(epoch_acc), epoch)\n",
        "            if phase=='test':\n",
        "                log_scalar('test_loss', epoch_loss, epoch)\n",
        "                log_scalar('test_accuracy', float(epoch_acc), epoch)\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            if phase == 'test' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'test':\n",
        "                test_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    mlflow.log_param('Training time',time_elapsed)\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best test Acc: {:4f}'.format(best_acc))\n",
        "    mlflow.log_param('Best test Acc',float(best_acc))\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, test_acc_history"
      ],
      "metadata": {
        "id": "dUbf1gAObKQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "metadata": {
        "id": "ces9YmhubnzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"resnet\":\n",
        "        \"\"\" resnet152\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet152(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"alexnet\":\n",
        "        \"\"\" Alexnet\n",
        "        \"\"\"\n",
        "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"vgg16\":\n",
        "        \"\"\" VGG16_bn\n",
        "        \"\"\"\n",
        "        model_ft = models.vgg16(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"squeezenet\":\n",
        "        \"\"\" Squeezenet\n",
        "        \"\"\"\n",
        "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
        "        model_ft.num_classes = num_classes\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"densenet\":\n",
        "        \"\"\" Densenet201\n",
        "        \"\"\"\n",
        "        model_ft = models.densenet201(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier.in_features\n",
        "        model_ft.classifier = nn.Linear(num_ftrs, num_classes) \n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"inception\":\n",
        "        \"\"\" Inception v3 \n",
        "        Be careful, expects (299,299) sized images and has auxiliary output\n",
        "        \"\"\"\n",
        "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "\n",
        "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
        "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 299\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "    \n",
        "    return model_ft, input_size\n",
        "\n",
        "# Initialize the model for this run\n",
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=pre_trained)\n",
        "\n",
        "# Print the model we just instantiated\n",
        "print(model_ft)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ATc8XXtbn1f",
        "outputId": "80f2852f-1b7e-4b0b-948e-a10273b639a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data augmentation and normalization for training"
      ],
      "metadata": {
        "id": "T8jNe-4KceqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.RandomResizedCrop(input_size),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "print(\"Initializing Datasets and Dataloaders...\")\n",
        "\n",
        "\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'test']}\n",
        "\n",
        "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'test']}\n",
        "\n",
        "# Detect if we have a GPU available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnZczzLZbw7H",
        "outputId": "966dbecd-5025-425f-f191-d5bb27e47658"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Datasets and Dataloaders...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observing that all parameters are being optimized"
      ],
      "metadata": {
        "id": "LOFmk5o0ckvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = model_ft.to(device)\n",
        "\n",
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INS8xAu0bw92",
        "outputId": "af1be72c-8bbd-421e-dc2a-012124bc51d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Params to learn:\n",
            "\t features.0.weight\n",
            "\t features.0.bias\n",
            "\t features.3.weight\n",
            "\t features.3.bias\n",
            "\t features.6.weight\n",
            "\t features.6.bias\n",
            "\t features.8.weight\n",
            "\t features.8.bias\n",
            "\t features.10.weight\n",
            "\t features.10.bias\n",
            "\t classifier.1.weight\n",
            "\t classifier.1.bias\n",
            "\t classifier.4.weight\n",
            "\t classifier.4.bias\n",
            "\t classifier.6.weight\n",
            "\t classifier.6.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with mlflow.start_run() as run:\n",
        "    mlflow.log_param('dataset', data_dir)\n",
        "    mlflow.log_param('model name', model_name)\n",
        "    mlflow.log_param('number of classes', num_classes)\n",
        "    mlflow.log_param('Batch size', batch_size)\n",
        "    mlflow.log_param('epochs', num_epochs)\n",
        "    mlflow.log_param('feature extracted', feature_extract)\n",
        "    mlflow.log_param('pre-trained', pre_trained)\n",
        "    # Setup the loss fxn\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Train and evaluate\n",
        "    model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))\n",
        "    mlflow.pytorch.log_model(model_ft,\"models\")\n",
        "    mlflow.pytorch.save_model(model_ft,save_model+today+'/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sx-3j-rSbxAW",
        "outputId": "b4f9c0a5-0f8a-4092-ca1d-349a0722fd77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.5456 Acc: 0.7867\n",
            "test Loss: 0.5952 Acc: 0.6500\n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.5219 Acc: 0.8167\n",
            "test Loss: 0.8630 Acc: 0.3833\n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.5406 Acc: 0.8033\n",
            "test Loss: 0.4368 Acc: 0.8333\n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.4663 Acc: 0.8100\n",
            "test Loss: 0.4148 Acc: 0.8333\n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.4418 Acc: 0.8333\n",
            "test Loss: 0.3983 Acc: 0.8333\n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.4270 Acc: 0.8267\n",
            "test Loss: 0.3683 Acc: 0.8333\n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.4235 Acc: 0.8333\n",
            "test Loss: 0.3652 Acc: 0.8500\n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.4138 Acc: 0.8467\n",
            "test Loss: 0.3546 Acc: 0.8500\n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.4313 Acc: 0.8267\n",
            "test Loss: 0.3377 Acc: 0.9000\n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.4468 Acc: 0.8333\n",
            "test Loss: 0.4099 Acc: 0.8833\n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.4215 Acc: 0.8367\n",
            "test Loss: 0.3482 Acc: 0.8333\n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.4343 Acc: 0.8333\n",
            "test Loss: 0.3805 Acc: 0.8500\n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.4183 Acc: 0.8333\n",
            "test Loss: 0.3725 Acc: 0.8500\n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.3986 Acc: 0.8400\n",
            "test Loss: 0.3680 Acc: 0.8500\n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.3829 Acc: 0.8433\n",
            "test Loss: 0.3552 Acc: 0.8667\n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.3871 Acc: 0.8433\n",
            "test Loss: 0.3222 Acc: 0.8833\n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.3613 Acc: 0.8667\n",
            "test Loss: 0.2811 Acc: 0.8833\n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.3652 Acc: 0.8433\n",
            "test Loss: 0.4279 Acc: 0.8500\n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.5039 Acc: 0.8000\n",
            "test Loss: 0.4071 Acc: 0.8333\n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.4185 Acc: 0.8500\n",
            "test Loss: 0.2992 Acc: 0.8500\n",
            "\n",
            "Training complete in 3m 14s\n",
            "Best test Acc: 0.900000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023/04/02 19:43:31 WARNING mlflow.utils.requirements_utils: Found torch version (1.13.1+cu116) contains a local version label (+cu116). MLflow logged a pip requirement for this package as 'torch==1.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
            "2023/04/02 19:43:35 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.14.1+cu116) contains a local version label (+cu116). MLflow logged a pip requirement for this package as 'torchvision==0.14.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
            "2023/04/02 19:43:37 WARNING mlflow.utils.requirements_utils: Found torch version (1.13.1+cu116) contains a local version label (+cu116). MLflow logged a pip requirement for this package as 'torch==1.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
            "2023/04/02 19:43:42 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.14.1+cu116) contains a local version label (+cu116). MLflow logged a pip requirement for this package as 'torchvision==0.14.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Confusion Matrix Pipeline"
      ],
      "metadata": {
        "id": "4Mo2ol0wc1za"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix = torch.zeros(num_classes, num_classes)\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, classes) in enumerate(dataloaders_dict['test']):\n",
        "        inputs = inputs.to(device)\n",
        "        classes = classes.to(device)\n",
        "        outputs = model_ft(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1"
      ],
      "metadata": {
        "id": "Jey8pRGUdENv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "classes=[\"good\",\"not-good\"]\n",
        "df_cm = pd.DataFrame(confusion_matrix.numpy(), index = [i for i in classes],\n",
        "                  columns = [i for i in classes])"
      ],
      "metadata": {
        "id": "qqGJNVoFga1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cm=df_cm.astype(np.int64)"
      ],
      "metadata": {
        "id": "wtCWSsUCga3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cm.to_csv(save_confusion_mat)"
      ],
      "metadata": {
        "id": "oE77d--4ga5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.figure(figsize = (16,8)) \n",
        "f, ax = plt.subplots(figsize=(18, 10))\n",
        "sns.heatmap(df_cm,annot=True, fmt=\"d\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "q8S4SHzYgmyX",
        "outputId": "c6d01f58-54f6-4970-d418-2ff18c5619c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 69
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}